{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82581ee",
   "metadata": {},
   "source": [
    "# Genetic Algorithm for Strong Lottery Tickets — Moons Dataset\n",
    "\n",
    "Evolves binary masks over a **fixed, randomly-initialised MLP** to find\n",
    "sub-networks that classify the scikit-learn *moons* dataset **without any\n",
    "weight training** (Strong Lottery Ticket).\n",
    "\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| Dataset | `make_moons` (1 000 samples, noise = 0.3) |\n",
    "| Model | MLP 2 → 32 → 32 → 32 → 2 (~1 274 params) |\n",
    "| Init | Uniform [-1, 1] |\n",
    "| Pop / Gens | 100 / 100 – 200 |\n",
    "| Fitness | Accuracy (binary task) |\n",
    "| Post-prune | configurable |\n",
    "\n",
    "**GA hyper-parameters** (paper defaults):\n",
    "rec_rate = 0.3, mut_rate = 0.1, mig_rate = 0.1,\n",
    "par_rate = 0.3, stagnation = 50 generations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf45c4",
   "metadata": {},
   "source": [
    "## 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Project root\n",
    "ROOT = Path(os.getcwd()).parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.util import set_seed, get_prunable_layers, apply_masks_to_model\n",
    "from src.ga import GAConfig, GeneticAlgorithmPruner, bitvector_to_masks, _evaluate_mask_on_data\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c568aa",
   "metadata": {},
   "source": [
    "## 2 — Dataset (moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# Generate moons dataset: 1000 samples, noise=0.3 (as per paper)\n",
    "X, y = make_moons(n_samples=1000, noise=0.3, random_state=SEED)\n",
    "\n",
    "# 80/20 train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "y_train_t = torch.from_numpy(y_train).long()\n",
    "X_test_t  = torch.from_numpy(X_test).float()\n",
    "y_test_t  = torch.from_numpy(y_test).long()\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_t,  y_test_t),  batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples  |  Test: {len(X_test)} samples\")\n",
    "\n",
    "# Quick scatter plot\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='coolwarm', s=8, alpha=0.6)\n",
    "ax.set_title(\"Moons — training set\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5557d6",
   "metadata": {},
   "source": [
    "## 3 — Model definition\n",
    "\n",
    "Feedforward MLP: **2 → 32 → 32 → 32 → 2** with ReLU activations.\n",
    "Weights initialised uniformly from **[-1, 1]** (paper default).\n",
    "Biases initialised but **not pruned** (only `nn.Linear` weights are prunable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonsMLP(nn.Module):\n",
    "    \"\"\"Small MLP for the moons binary classification task.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return self.fc4(x)\n",
    "\n",
    "\n",
    "def make_model(seed=42):\n",
    "    \"\"\"Create MLP with uniform [-1, 1] weight init.\"\"\"\n",
    "    set_seed(seed)\n",
    "    model = MoonsMLP().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.uniform_(m.weight, -1.0, 1.0)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.uniform_(m.bias, -1.0, 1.0)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_model(SEED)\n",
    "\n",
    "# Count parameters\n",
    "prunable = get_prunable_layers(model)\n",
    "total_prunable = sum(w.size for w in prunable.values())\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters   : {total_params:,}\")\n",
    "print(f\"Prunable (weights) : {total_prunable:,}\")\n",
    "print(f\"Layers: {list(prunable.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4716ca41",
   "metadata": {},
   "source": [
    "## 4 — GA configuration & run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880855c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_config = GAConfig(\n",
    "    population_size=100,\n",
    "    rec_rate=0.3,\n",
    "    mut_rate=0.1,\n",
    "    mig_rate=0.1,\n",
    "    par_rate=0.3,\n",
    "    min_generations=100,\n",
    "    max_generations=200,\n",
    "    stagnation_threshold=50,\n",
    "    use_adaptive_ab=False,       # plain GA variant (baseline)\n",
    "    use_loss_fitness=False,      # use accuracy for binary task\n",
    "    max_eval_batches=None,       # evaluate on full training set\n",
    "    post_prune=False,            # disable post-pruning for initial run\n",
    ")\n",
    "\n",
    "pruner = GeneticAlgorithmPruner(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    device=DEVICE,\n",
    "    config=ga_config,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "best_masks, ga_stats = pruner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a30e98",
   "metadata": {},
   "source": [
    "## 5 — Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e5bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best mask on the TEST set (unseen data)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_acc = _evaluate_mask_on_data(\n",
    "    model, best_masks, test_loader, criterion, DEVICE\n",
    ")\n",
    "train_loss, train_acc = _evaluate_mask_on_data(\n",
    "    model, best_masks, train_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "sparsity = ga_stats['best_sparsity']\n",
    "\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  GA Result (no weight training)\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Train accuracy : {train_acc:.2f}%\")\n",
    "print(f\"  Test accuracy  : {test_acc:.2f}%\")\n",
    "print(f\"  Sparsity       : {sparsity:.2%}\")\n",
    "print(f\"  Generations    : {ga_stats['total_generations']}\")\n",
    "print(f\"  Time           : {ga_stats['total_time_seconds']:.1f}s\")\n",
    "print(f\"  Cache entries  : {ga_stats['cache_entries']}\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24336ce",
   "metadata": {},
   "source": [
    "## 6 — Visualise GA evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f50f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gens_hist = ga_stats['generations']\n",
    "gens      = [g['generation'] for g in gens_hist]\n",
    "best_perf = [g['best_perf'] for g in gens_hist]\n",
    "mean_perf = [g['mean_perf'] for g in gens_hist]\n",
    "best_sp   = [g['best_sparsity'] for g in gens_hist]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Fitness over generations\n",
    "ax1.plot(gens, best_perf, label='best', linewidth=2)\n",
    "ax1.plot(gens, mean_perf, '--', label='mean', alpha=0.6)\n",
    "ax1.set_xlabel('Generation')\n",
    "ax1.set_ylabel('Fitness (accuracy %)')\n",
    "ax1.set_title('GA Evolution — Fitness')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Sparsity over generations\n",
    "ax2.plot(gens, [s * 100 for s in best_sp], color='tab:orange', linewidth=2)\n",
    "ax2.set_xlabel('Generation')\n",
    "ax2.set_ylabel('Sparsity (%)')\n",
    "ax2.set_title('GA Evolution — Best Sparsity')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba200a90",
   "metadata": {},
   "source": [
    "## 7 — Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b06fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundary of the discovered sub-network\n",
    "def plot_decision_boundary(model, masks, X, y, title=\"Decision Boundary\"):\n",
    "    apply_masks_to_model(model, masks)\n",
    "    model.eval()\n",
    "\n",
    "    h = 0.05\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    grid = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float().to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(grid).argmax(dim=1).cpu().numpy()\n",
    "    Z = preds.reshape(xx.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', s=12, edgecolors='k', linewidths=0.3)\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Reload clean model weights, then visualise\n",
    "model = make_model(SEED)\n",
    "plot_decision_boundary(model, best_masks, X_test, y_test,\n",
    "                       title=f\"GA sub-network — test acc {test_acc:.1f}%, sparsity {sparsity:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8df829",
   "metadata": {},
   "source": [
    "## 8 — Post-evolutionary pruning comparison\n",
    "\n",
    "Re-run with `post_prune=True` to see how much extra sparsity the sequential\n",
    "bit-zeroing step can add without hurting accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run GA with post-evolutionary pruning enabled\n",
    "model_pp = make_model(SEED)\n",
    "\n",
    "ga_config_pp = GAConfig(\n",
    "    population_size=100,\n",
    "    rec_rate=0.3,\n",
    "    mut_rate=0.1,\n",
    "    mig_rate=0.1,\n",
    "    par_rate=0.3,\n",
    "    min_generations=100,\n",
    "    max_generations=200,\n",
    "    stagnation_threshold=50,\n",
    "    use_adaptive_ab=False,\n",
    "    use_loss_fitness=False,\n",
    "    max_eval_batches=None,\n",
    "    post_prune=True,              # <-- enable post-pruning\n",
    ")\n",
    "\n",
    "pruner_pp = GeneticAlgorithmPruner(\n",
    "    model=model_pp,\n",
    "    train_loader=train_loader,\n",
    "    device=DEVICE,\n",
    "    config=ga_config_pp,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "best_masks_pp, ga_stats_pp = pruner_pp.run()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss_pp, test_acc_pp = _evaluate_mask_on_data(\n",
    "    model_pp, best_masks_pp, test_loader, criterion, DEVICE\n",
    ")\n",
    "sparsity_pp = ga_stats_pp['best_sparsity']\n",
    "\n",
    "# Compare\n",
    "print(f\"\\n{'='*55}\")\n",
    "print(f\"  {'Metric':<20} {'No post-prune':>15} {'Post-prune':>15}\")\n",
    "print(f\"  {'-'*50}\")\n",
    "print(f\"  {'Test accuracy':<20} {test_acc:>14.2f}% {test_acc_pp:>14.2f}%\")\n",
    "print(f\"  {'Sparsity':<20} {sparsity:>14.2%} {sparsity_pp:>14.2%}\")\n",
    "print(f\"  {'Generations':<20} {ga_stats['total_generations']:>15d} {ga_stats_pp['total_generations']:>15d}\")\n",
    "print(f\"  {'Time (s)':<20} {ga_stats['total_time_seconds']:>15.1f} {ga_stats_pp['total_time_seconds']:>15.1f}\")\n",
    "print(f\"{'='*55}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
