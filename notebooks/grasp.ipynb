{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e601d2c",
   "metadata": {},
   "source": [
    "# GraSP Experiment — VGG-19 on CIFAR-10\n",
    "\n",
    "Reproducing the core result from *Picking Winning Tickets Before Training by Preserving Gradient Flow* (Wang et al., 2020).\n",
    "\n",
    "| Setting | Value |\n",
    "|---|---|\n",
    "| **Architecture** | VGG-19 (with BatchNorm) |\n",
    "| **Dataset** | CIFAR-10 |\n",
    "| **Initialization** | Kaiming Normal |\n",
    "| **GraSP pruning batch** | 100 samples (10 × 10 classes) |\n",
    "| **Optimizer** | SGD, momentum 0.9, weight decay 1e-4 |\n",
    "| **Epochs** | 160 |\n",
    "| **Batch size** | 128 |\n",
    "| **Learning rate** | 0.1 → ×0.1 at epochs 80, 120 |\n",
    "| **Sparsities** | 90 %, 95 %, 98 % |\n",
    "\n",
    "We compare **Dense** (unpruned) vs several GraSP sparsity levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef015a",
   "metadata": {},
   "source": [
    "## 1 — Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea23131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, copy, json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Project imports\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from model import vgg19, count_parameters\n",
    "from grasp import grasp, get_grasp_sparsity\n",
    "from train import train_epochs, evaluate\n",
    "from util import apply_masks_to_model, create_mask_apply_fn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e76238e",
   "metadata": {},
   "source": [
    "## 2 — Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Model / dataset\n",
    "    'model':        'vgg19',\n",
    "    'dataset':      'cifar10',\n",
    "    'num_classes':  10,\n",
    "\n",
    "    # GraSP pruning\n",
    "    'sparsities':   [0.0, 0.90, 0.95, 0.98],   # 0.0 = dense baseline\n",
    "    'samples_per_class': 10,                     # 10 × 10 classes = 100 samples\n",
    "    'grasp_T':      200,                         # temperature scaling\n",
    "    'grasp_iters':  1,                            # number of balanced batches\n",
    "\n",
    "    # Training\n",
    "    'epochs':       160,\n",
    "    'batch_size':   128,\n",
    "    'lr':           0.1,\n",
    "    'momentum':     0.9,\n",
    "    'weight_decay': 1e-4,\n",
    "    'lr_milestones': [80, 120],\n",
    "    'lr_gamma':     0.1,\n",
    "\n",
    "    # Reproducibility\n",
    "    'seed':         42,\n",
    "\n",
    "    # Output\n",
    "    'results_dir':  '../results/grasp',\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"EXPERIMENT CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "for k, v in config.items():\n",
    "    print(f\"  {k:>20s}: {v}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c04f3",
   "metadata": {},
   "source": [
    "## 3 — Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 transforms (standard augmentation for training)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                          (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                          (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='../data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='../data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],\n",
    "                          shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256,\n",
    "                          shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Training samples : {len(train_dataset):,}\")\n",
    "print(f\"Test samples     : {len(test_dataset):,}\")\n",
    "print(f\"Training batches : {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6323b1",
   "metadata": {},
   "source": [
    "## 4 — Helper: train one configuration end-to-end\n",
    "\n",
    "Encapsulates: model init → (optional) GraSP pruning → full 160-epoch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(sparsity: float, config: dict):\n",
    "    \"\"\"Create model, optionally apply GraSP, then train for 160 epochs.\n",
    "\n",
    "    Returns a dict with training history, final accuracy, and mask info.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(config['seed'])\n",
    "    np.random.seed(config['seed'])\n",
    "    torch.cuda.manual_seed_all(config['seed'])\n",
    "\n",
    "    # ---- Model (Kaiming Normal init) ----\n",
    "    model = vgg19(num_classes=config['num_classes']).to(device)\n",
    "\n",
    "    # Apply Kaiming Normal to all Conv2d layers\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    params = count_parameters(model)\n",
    "    tag = f\"dense\" if sparsity == 0.0 else f\"sparse_{sparsity}\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"[{tag}]  sparsity = {sparsity*100:.0f}%\")\n",
    "    print(f\"  Total params: {params['total']:,}\")\n",
    "\n",
    "    # ---- GraSP pruning (skip for dense baseline) ----\n",
    "    masks = None\n",
    "    apply_fn = None\n",
    "\n",
    "    if sparsity > 0:\n",
    "        print(f\"  Running GraSP (T={config['grasp_T']}, \"\n",
    "              f\"samples={config['samples_per_class']*config['num_classes']}) …\")\n",
    "        masks = grasp(\n",
    "            model, train_loader, device,\n",
    "            sparsity=sparsity,\n",
    "            num_classes=config['num_classes'],\n",
    "            samples_per_class=config['samples_per_class'],\n",
    "            num_iters=config['grasp_iters'],\n",
    "            T=config['grasp_T'],\n",
    "        )\n",
    "        layer_sparsity = get_grasp_sparsity(masks)\n",
    "        print(f\"  Achieved overall sparsity: {layer_sparsity['overall']*100:.2f}%\")\n",
    "        for name, sp in layer_sparsity.items():\n",
    "            if name != 'overall':\n",
    "                print(f\"    {name:>30s}: {sp*100:.2f}%\")\n",
    "\n",
    "        # Build mask-application closure\n",
    "        apply_fn = create_mask_apply_fn(model)\n",
    "\n",
    "    # ---- Optimizer / scheduler ----\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        momentum=config['momentum'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "    )\n",
    "    scheduler = MultiStepLR(optimizer,\n",
    "                            milestones=config['lr_milestones'],\n",
    "                            gamma=config['lr_gamma'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- Train ----\n",
    "    print(f\"  Training for {config['epochs']} epochs …\")\n",
    "    history = train_epochs(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        num_epochs=config['epochs'],\n",
    "        device=device,\n",
    "        scheduler=scheduler,\n",
    "        masks=masks,\n",
    "        apply_mask_fn=apply_fn,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    best_test = max(history['test_accs'])\n",
    "    final_test = history['final_test_acc']\n",
    "    print(f\"  ✓ Done — best test acc: {best_test:.2f}%, \"\n",
    "          f\"final test acc: {final_test:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        'sparsity': sparsity,\n",
    "        'history': history,\n",
    "        'best_test_acc': best_test,\n",
    "        'final_test_acc': final_test,\n",
    "        'masks': masks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21905afa",
   "metadata": {},
   "source": [
    "## 5 — Run experiments\n",
    "\n",
    "Train the dense baseline and each GraSP sparsity level sequentially.\n",
    "This is the long-running cell (≈ 4 × 160 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326941d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}\n",
    "\n",
    "for sparsity in config['sparsities']:\n",
    "    tag = \"dense\" if sparsity == 0.0 else f\"{sparsity*100:.0f}%\"\n",
    "    result = run_experiment(sparsity, config)\n",
    "    all_results[tag] = result\n",
    "\n",
    "# ---------- save results to disk ----------\n",
    "os.makedirs(config['results_dir'], exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_path = os.path.join(config['results_dir'], f\"grasp_vgg19_cifar10_{timestamp}.json\")\n",
    "\n",
    "serialisable = {}\n",
    "for tag, res in all_results.items():\n",
    "    serialisable[tag] = {\n",
    "        'sparsity': res['sparsity'],\n",
    "        'best_test_acc': res['best_test_acc'],\n",
    "        'final_test_acc': res['final_test_acc'],\n",
    "        'test_accs': res['history']['test_accs'],\n",
    "        'train_accs': res['history']['train_accs'],\n",
    "        'train_losses': res['history']['train_losses'],\n",
    "    }\n",
    "\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(serialisable, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to {save_path}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Sparsity':>12s}  {'Best Test Acc':>14s}  {'Final Test Acc':>14s}\")\n",
    "print(\"-\" * 44)\n",
    "for tag, res in all_results.items():\n",
    "    print(f\"{tag:>12s}  {res['best_test_acc']:>13.2f}%  {res['final_test_acc']:>13.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d71e0",
   "metadata": {},
   "source": [
    "## 6 — Visualise results\n",
    "\n",
    "**Left**: test accuracy curves over 160 epochs for each sparsity level.\n",
    "**Right**: best test accuracy vs sparsity (the key plot for comparing with the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ffd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "colors = {\n",
    "    'dense':  '#2E86AB',\n",
    "    '90%':    '#A23B72',\n",
    "    '95%':    '#F18F01',\n",
    "    '98%':    '#C73E1D',\n",
    "}\n",
    "\n",
    "# ---- Plot 1: test accuracy over epochs ----\n",
    "for tag, res in all_results.items():\n",
    "    epochs = range(1, len(res['history']['test_accs']) + 1)\n",
    "    ax1.plot(epochs, res['history']['test_accs'],\n",
    "             label=f\"{tag} (best {res['best_test_acc']:.2f}%)\",\n",
    "             color=colors.get(tag, 'gray'), linewidth=1.5)\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('VGG-19 / CIFAR-10 — Test Accuracy over Training', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# ---- Plot 2: best accuracy vs sparsity ----\n",
    "sparsities_pct = []\n",
    "best_accs = []\n",
    "for tag, res in all_results.items():\n",
    "    sp = res['sparsity'] * 100\n",
    "    sparsities_pct.append(sp)\n",
    "    best_accs.append(res['best_test_acc'])\n",
    "\n",
    "ax2.plot(sparsities_pct, best_accs, 'o-', linewidth=2, markersize=8, color='#2E86AB')\n",
    "for sp, acc in zip(sparsities_pct, best_accs):\n",
    "    ax2.annotate(f'{acc:.2f}%', (sp, acc), textcoords='offset points',\n",
    "                 xytext=(0, 10), ha='center', fontsize=9,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', fc='lightyellow', alpha=0.8))\n",
    "\n",
    "ax2.set_xlabel('Sparsity (%)', fontsize=12)\n",
    "ax2.set_ylabel('Best Test Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('GraSP: Accuracy vs Sparsity', fontsize=13, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config['results_dir'], 'grasp_vgg19_cifar10.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Final table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL RESULTS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Sparsity':>12s}  {'Best Test Acc':>14s}  {'Final Test Acc':>14s}\")\n",
    "print(\"-\" * 44)\n",
    "for tag, res in all_results.items():\n",
    "    print(f\"{tag:>12s}  {res['best_test_acc']:>13.2f}%  {res['final_test_acc']:>13.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
